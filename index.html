<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Win Fast or Lose Slow</title>
  <link href="https://fonts.googleapis.com/css2?family=Dancing+Script:wght@400;700&family=Great+Vibes&family=Pacifico&display=swap" rel="stylesheet">
  <style>
    body {
      font-family: sans-serif;
      margin: 0;
      padding: 0;
      text-align: center;
    }
    .title {
      margin-top: 50px;
      font-size: 36px;
      font-weight: bold;
    }
    .authors {
      font-size: 26px;
      margin: 10px 0;
    }
    .authors a {
      color: #0074D9;
      text-decoration: none;
    }
    .affiliations {
      font-size: 20px;
      color: #555;
      margin-bottom: 5px;
    }
    .emails {
      font-size: 24px;
      color: #444;
    }
    .buttons {
      margin: 20px 0;
    }
    .buttons a {
      text-decoration: none;
      display: inline-block;
      margin: 5px;
      padding: 10px 20px;
      background: black;
      color: white;
      border-radius: 20px;
    }
    .figures {
      display: flex;
      justify-content: center;
      flex-wrap: wrap;
      gap: 10px;
      margin: 40px auto;
      max-width: 900px;
    }
    .figures img {
      width: 90%;
      border: 1px solid #ccc;
    }
    .figures-small {
      display: flex;
      flex-direction: column;
      align-items: flex-start;
      gap: 10px;
      margin: 40px auto;
      max-width: 600px;
      padding: 0 20px;
      text-align: left;
    }
    .figures-small img {
      width: 60%;
      border: 1px solid #ccc;
    }
    .figures-small h2 {
      text-align: left;
    }
    .cursive {
      font-family: 'Brush Script MT', cursive;
      font-style: italic;
    }
    .fancy {
      font-family: 'Lucida Handwriting', 'Brush Script MT', cursive;
      font-style: italic;
    }
    .script {
      font-family: 'Dancing Script', 'Brush Script MT', cursive;
      font-style: italic;
    }
    .italic-x {
      font-style: italic;
      font-family: serif;
    }
    .section {
      max-width: 800px;
      margin: 40px auto;
      text-align: left;
      padding: 0 20px;
    }
    .section h2 {
      border-bottom: 2px solid #eee;
      padding-bottom: 5px;
    }
  </style>
</head>
<body>
  <div class="title">Win Fast or Lose Slow: <span class="script">Balancing Speed and Accuracy in Latency-Sensitive Decisions of LLMs</span></div>
  <div class="authors">
    <a href="https://haokang-timmy.github.io/">Hao Kang</a><sup>1</sup>, 
    <a href="https://www.linkedin.com/in/qingru-zhang-4b789a187">Qingru Zhang</a><sup>1</sup>, 
    <a href="https://han-cai.github.io/">Han Cai</a><sup>2</sup>, 
    <a href="#">Weiyuan Xu</a><sup>3</sup>, 
    <a href="https://tusharkrishna.ece.gatech.edu/">Tushar Krishna</a><sup>1</sup>, 
    <a href="https://yilundu.github.io/">Yilun Du</a><sup>4</sup>, 
    <a href="https://web.stanford.edu/~tsachy/">Tsachy Weissman</a><sup>5</sup>
  </div>
  <div class="affiliations">
    <sup>1</sup>Georgia Tech, <sup>2</sup>NVIDIA, <sup>3</sup>UC Berkeley, <sup>4</sup>Harvard University, <sup>5</sup>Stanford University
  </div>
  <div class="emails">
    Correspond to: hkang342@gatech.edu
  </div>

   <div class="buttons">
    <a href="https://arxiv.org/abs/2505.19481">arXiv</a>
    <a href="https://github.com/HaoKang-Timmy/LatencySensitiveBench">Code</a>
    <a href="#">Tweet</a>
  </div>

  
  <!-- <div class="section">
    <h2>StreetFighter</h2>
    <video src="https://github.com/user-attachments/assets/c69571df-f109-4e92-9e60-60a9cd7933f2" controls width="90%"></video>
  </div> -->
  <div class="section">
    <!-- <h2>HFTBench</h2> -->
    <!-- <img src="./Figs/HFTData.png" alt="CompetitiveAgents" controls width="90%"> -->


    <video src="https://github.com/user-attachments/assets/29ac29d2-041c-492a-a142-c51c22e74e41" controls width="90%"></video>
  </div>
  <div class="section">
    <h2>Abstract</h2>
    <p>Large language models (LLMs) have shown remarkable performance across diverse reasoning and generation tasks, and are increasingly deployed as agents in dynamic environments such as code generation and recommendation systems. However, many real-world applications, such as high-frequency trading and real-time competitive gaming, require decisions under strict latency constraints, where faster responses directly translate into higher rewards.</p>

      <p></p>Despite the importance of this latency-quality trade-off, it remains underexplored in the context of LLM-based agents. In this work, we present the first systematic study of this trade-off in real-time decision-making tasks.</p>
      
      <p>To support our investigation, we introduce two new benchmarks: <strong>HFTBench</strong>, a high-frequency trading simulation, and <strong>StreetFighter</strong>, a competitive gaming platform. We also designe a new mixed-precision inference framework, <strong>FP<span class="italic-x">X</span></strong>, to enable fine-grained latency-quality trade-offs for LLM agents. Our analysis reveals that optimal latency-quality balance varies by task, and that sacrificing quality for lower latency can significantly enhance downstream performance.</p>
  </div>
  <div class="figures">
    <img src="./Figs/FiguresTogether.png" alt="CompetitiveAgents">
  </div>
  <!-- <div class="section">
    <h2>Introduction</h2>
    <p>We propose a new benchmark for evaluating the speed-accuracy tradeoffs of LLM agents in latency-sensitive tasks, where the speed and accuracy of the agent are both important. Our benchmark consists of two tasks: StreetFighter, a competitive game, and HFTBench, a high-frequency trading task. We evaluate the performance of LLM agents on these tasks using three different model size and inference bitwidths. We find that the speed-accuracy tradeoffs of LLM agents are significantly different depending on the serving method. Our benchmark provides a new perspective on the speed-accuracy tradeoffs of LLM agents and can be used to guide the development of more efficient and accurate LLM agents.</p>
  </div> -->
  <div class="section" style="padding: 2rem; font-family: sans-serif; max-width: 800px; margin: auto;">
    <h2 style="font-size: 2rem; margin-bottom: 1rem;">Introduction</h2>
    <p style="font-size: 1.1rem; line-height: 1.6;">
      <strong>LLM agents don't just need to think, they need to act <em>fast</em>.</strong> In real-time settings like 
      <strong>high-frequency trading</strong> and <strong>competitive gaming</strong>, speed and quality go hand-in-hand.
    </p>
    <p style="font-size: 1.1rem; line-height: 1.6;">
      We introduce two benchmarks that push LLMs into latency-critical roles: <strong>StreetFighter</strong>, a fast-paced fighting game, and 
      <strong>HFTBench</strong>, a high-frequency trading simulator. Each task exposes different sensitivity to inference latency 
      and output quality.
    </p>
    <p style="font-size: 1.1rem; line-height: 1.6;">
      To address and evaluate these trade-offs, we propose <code style="background: #f4f4f4; padding: 0 0.2rem;">FP<span class="italic-x">X</span></code>, an adaptive 
      mixed-precision inference framework that dynamically balances <strong>model size</strong> and <strong>bitwidth</strong>. 
      This allows fine-grained control over speed–quality balance, helping agents stay competitive under tight timing constraints.
    </p>
    <p style="font-size: 1.1rem; line-height: 1.6;">
      Our findings reveal that faster isn't always worse, and smarter isn't always slower. This work opens the door to 
      <strong>latency-aware design</strong> for future intelligent agents.
    </p>
  </div>
  <div class="section" style="padding: 2rem; font-family: sans-serif; max-width: 800px; margin: auto;">
    <h2 style="font-size: 2rem; margin-bottom: 1rem;">Latency-Sensitive Benchmarks</h2>
    <p style="font-size: 1.1rem; line-height: 1.6;">
      To evaluate LLM agents in real-time scenarios, we introduce two custom benchmarks:
    </p>
    <ul style="font-size: 1.1rem; line-height: 1.6; padding-left: 1.2rem;">
      <li>
        <strong>Street Fighter</strong>: A real-time gaming environment where agents must respond quickly and strategically in competitive matches.
      </li>
      <li>
        <strong>HFTBench</strong>: A high-frequency trading simulation that tests how fast and accurately agents can make financial decisions in dynamic markets.
      </li>
    </ul>
    <p style="font-size: 1.1rem; line-height: 1.6;">
      These benchmarks capture different types of latency-sensitive decision-making and provide a testbed for evaluating the speed–quality trade-off in LLM-based agents.
    </p>
  </div>
  <div class="section">
    <h2>StreetFighter</h2>
    <video src="https://github.com/user-attachments/assets/c69571df-f109-4e92-9e60-60a9cd7933f2" controls width="90%"></video>
  </div>  
  <div class="section">
    <h2>HFTBench</h2>
    <img src="./Figs/HFTData.png" alt="CompetitiveAgents" controls width="90%">
  </div>  
  <!-- <div class="figures">
    <img src="./Figs/Benchmarks.png" alt="CompetitiveAgents">
  </div> -->
  <div class="section" style="padding: 2rem; font-family: sans-serif; max-width: 800px; margin: auto;">
    <h2 style="font-size: 2rem; margin-bottom: 1rem;">What is FP<span class="italic-x">X</span>?</h2>
    <p style="font-size: 1.1rem; line-height: 1.6;">
      <strong>FP<span class="italic-x">X</span></strong> is our adaptive mixed-precision inference algorithm that enables <strong>fine-grained latency–quality trade-offs</strong> for LLM agents. Instead of compressing entire models, FP<span class="italic-x">X</span> selectively applies <code style="background: #f4f4f4; padding: 0 0.2rem;">FP4</code> only to layers that tolerate it best, while keeping <code style="background: #f4f4f4; padding: 0 0.2rem;">FP8</code> for sensitive components.
    </p>
    <p style="font-size: 1.1rem; line-height: 1.6;">
      Using a one-time offline calibration step, FP<span class="italic-x">X</span> measures the quantization error of each linear layer, then assigns lower precision to the most robust ones—achieving <strong>significant latency reduction</strong> with <strong>minimal accuracy loss</strong>.
    </p>
    <p style="font-size: 1.1rem; line-height: 1.6;">
      This targeted approach enables LLM agents to respond faster in real-time environments like trading or gaming, without sacrificing decision quality.
    </p>
  </div>
  <div class="figures">
    <img src="./Figs/Method.png" alt="FPX Method" style="width: 100%; max-width: 600px; margin: 1rem 0;">
  </div>
  <div class="section" style="padding: 2rem; font-family: sans-serif; max-width: 900px; margin: auto;">
    <h2>Evaluation</h2>
    <p style="font-size: 1.1rem; line-height: 1.6;">
      We evaluate our method on two latency-sensitive benchmarks: <strong>HFTBench</strong> for high-frequency trading and <strong>Street Fighter</strong> for real-time gaming. Our method dynamically adjusts model bitwidths to trade off latency and decision quality.
    </p>
  
    <h3 style="margin-top: 2rem;">📈 HFTBench</h3>
    <table border="1" cellpadding="8" cellspacing="0" style="border-collapse: collapse; width: 100%; font-size: 1rem;">
      <thead style="background-color: #f0f0f0;">
        <tr>
          <th>Model Size</th>
          <th>Bitwidth Avg</th>
          <th>Latency (ms) ↓</th>
          <th>Daily Yield (%) ↑</th>
        </tr>
      </thead>
      <tbody>
        <tr><td>14B (ours)</td><td>7.2</td><td>713</td><td><strong>26.52</strong></td></tr>
        <tr><td>14B</td><td>8</td><td>801</td><td>23.14</td></tr>
        <tr><td>14B</td><td>16</td><td>1302</td><td>17.20</td></tr>
        <tr><td>7B</td><td>16</td><td>619</td><td>-3.28</td></tr>
        <tr><td>7B (ours)</td><td>7.6</td><td>386</td><td>-7.25</td></tr>
        <tr><td>7B</td><td>8</td><td>394</td><td>-12.94</td></tr>
      </tbody>
    </table>
    <p style="font-size: 1.05rem; line-height: 1.6; margin-top: 1rem;">
      In <strong>HFTBench</strong>, larger models (e.g. 14B) consistently outperform smaller ones due to their superior ability to recognize profitable patterns. Speeding up weaker models like 7B does not help—poor decisions made faster often amplify losses. Our method improves 14B latency while retaining quality, achieving the best trade-off.
    </p>
  
    <h3 style="margin-top: 2rem;">🎮 Street Fighter</h3>
    <table border="1" cellpadding="8" cellspacing="0" style="border-collapse: collapse; width: 100%; font-size: 1rem;">
      <thead style="background-color: #f0f0f0;">
        <tr>
          <th>Model Size</th>
          <th>Bitwidth Avg</th>
          <th>Latency (ms) ↓</th>
          <th>ELO Score ↑</th>
        </tr>
      </thead>
      <tbody>
        <tr><td>3B (ours)</td><td>6.8</td><td>195</td><td><strong>5.99</strong></td></tr>
        <tr><td>7B (ours)</td><td>7.2</td><td>354</td><td>2.33</td></tr>
        <tr><td>3B</td><td>8</td><td>222</td><td>2.19</td></tr>
        <tr><td>3B</td><td>16</td><td>349</td><td>0.25</td></tr>
        <tr><td>7B</td><td>8</td><td>394</td><td>-0.44</td></tr>
        <tr><td>1.5B</td><td>8</td><td>142</td><td>-1.25</td></tr>
      </tbody>
    </table>
    <p style="font-size: 1.05rem; line-height: 1.6; margin-top: 1rem;">
      In <strong>Street Fighter</strong>, faster models tend to win more, but only up to a point. Because the game enforces a fixed frame rate (~200ms per action), making decisions faster than this brings no benefit. Smaller models like 1.5B are fast but lack strategy, while our compressed 3B model achieves the best balance of speed and quality.
    </p>
  </div>
  
  <div class="section">
    <h2>Paper & BibTeX</h2>
    <pre>
@misc{kang2025winfastloseslow,
  title={Win Fast or Lose Slow: Balancing Speed and Accuracy in Latency-Sensitive Decisions of LLMs},
  author={Hao Kang and Qingru Zhang and Han Cai and Weiyuan Xu and Tushar Krishna and Yilun Du and Tsachy Weissman},
  year={2025},
  eprint={2505.19481},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2505.19481},
}
    </pre>
  </div>

</body>
</html>
